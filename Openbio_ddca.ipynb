{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLrhFfUrqTS2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "df = pd.read_csv('/content/data.csv')\n",
        "\n",
        "# Step 2: Convert 'Diagnosis' to numerical values\n",
        "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
        "\n",
        "# Step 3: Calculate the centroid of the normal (Benign) data points\n",
        "normal_data = df[df['diagnosis'] == 0].drop(columns=['id', 'diagnosis'])  # Exclude 'id' and 'Diagnosis' columns\n",
        "centroid_normal = normal_data.mean().values  # Calculate the centroid (mean of normal data points)\n",
        "\n",
        "# Step 4: Calculate Euclidean distances for each data point from the centroid of normal points\n",
        "def calculate_euclidean_distance(row, centroid):\n",
        "    return euclidean(row.values, centroid)\n",
        "\n",
        "df['euclidean_distance'] = df.drop(columns=['id', 'diagnosis']).apply(lambda row: calculate_euclidean_distance(row, centroid_normal), axis=1)\n",
        "\n",
        "# Step 5: Normalize the distances to derive DS and SS\n",
        "# Normalize Euclidean distances to a [0, 1] range for DS and SS\n",
        "max_distance = df['euclidean_distance'].max()\n",
        "min_distance = df['euclidean_distance'].min()\n",
        "\n",
        "df['DS'] = (df['euclidean_distance'] - min_distance) / (max_distance - min_distance)  # Danger Signal\n",
        "df['SS'] = 1 - df['DS']  # Safe Signal (Inverse of Danger Signal)\n",
        "\n",
        "# Step 6: Initialize Dendritic Cells (DCs)\n",
        "num_dcs = 10\n",
        "dc_lifespan = np.random.uniform(10, 15, num_dcs)\n",
        "cumulative_csm = np.zeros(num_dcs)\n",
        "cumulative_k = np.zeros(num_dcs)\n",
        "dc_antigen_count = np.zeros(num_dcs)\n",
        "\n",
        "# Step 7: Calculate CSM and K for each DC\n",
        "for i in range(len(df)):\n",
        "    dc_index = i % num_dcs  # Assign antigen to a DC round-robin\n",
        "    csm = df['DS'].iloc[i] + df['SS'].iloc[i]\n",
        "    k = df['DS'].iloc[i] - 2 * df['SS'].iloc[i]\n",
        "\n",
        "    # Update cumulative values for DC\n",
        "    cumulative_csm[dc_index] += csm\n",
        "    cumulative_k[dc_index] += k\n",
        "    dc_antigen_count[dc_index] += 1\n",
        "\n",
        "    # Update DC lifespan\n",
        "    dc_lifespan[dc_index] -= csm\n",
        "    if dc_lifespan[dc_index] <= 0:\n",
        "        # Reset DC\n",
        "        dc_lifespan[dc_index] = np.random.uniform(10, 15)\n",
        "        cumulative_csm[dc_index] = 0\n",
        "        cumulative_k[dc_index] = 0\n",
        "        dc_antigen_count[dc_index] = 0\n",
        "\n",
        "# Step 8: Define threshold and classify based on K value\n",
        "# Let's assume if K > 0 it is classified as Malignant (anomalous), else Benign (normal)\n",
        "threshold = 0\n",
        "df['Predicted_M/B'] = np.where(cumulative_k > threshold, 1, 0)\n",
        "\n",
        "# Step 9: Calculate Accuracy\n",
        "accuracy = accuracy_score(df['Diagnosis'], df['Predicted_M/B'])\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Step 10: Save the results to a new CSV file\n",
        "df.to_csv('breast_cancer_with_predictions.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.spatial.distance import euclidean\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step 1: Load the dataset and handle missing values\n",
        "df = pd.read_csv('/content/data.csv')\n",
        "df.drop(columns=['Unnamed: 32'], inplace=True)  # Dropping irrelevant column\n",
        "\n",
        "# Step 2: Convert 'diagnosis' to numerical values (M = 1, B = 0)\n",
        "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
        "\n",
        "# Handle missing values using SimpleImputer (mean strategy)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df[df.columns] = imputer.fit_transform(df[df.columns])\n",
        "\n",
        "# Step 3: Compute correlation with the 'diagnosis' and select top features for DS and SS\n",
        "correlation_matrix = df.corr()\n",
        "class_correlation = correlation_matrix['diagnosis'].sort_values(ascending=False)\n",
        "best_features = class_correlation.index[1:5]  # Top 4 features most correlated with 'diagnosis'\n",
        "print(f\"Best Features based on correlation: {best_features}\")\n",
        "\n",
        "# Step 4: Standardize the selected features for DS and SS computation\n",
        "scaler = StandardScaler()\n",
        "df[best_features] = scaler.fit_transform(df[best_features])\n",
        "\n",
        "# Step 5: Calculate Euclidean distances for each data point from the centroid of normal (Benign) points\n",
        "normal_data = df[df['diagnosis'] == 0][best_features]\n",
        "centroid_normal = normal_data.mean().values  # Calculate the centroid (mean of normal data points)\n",
        "\n",
        "def calculate_euclidean_distance(row, centroid):\n",
        "    return euclidean(row.values, centroid)\n",
        "\n",
        "df['euclidean_distance'] = df[best_features].apply(lambda row: calculate_euclidean_distance(row, centroid_normal), axis=1)\n",
        "\n",
        "# Step 6: Normalize the distances to derive DS and SS\n",
        "max_distance = df['euclidean_distance'].max()\n",
        "min_distance = df['euclidean_distance'].min()\n",
        "\n",
        "df['DS'] = (df['euclidean_distance'] - min_distance) / (max_distance - min_distance)  # Danger Signal\n",
        "df['SS'] = 1 - df['DS']  # Safe Signal (Inverse of Danger Signal)\n",
        "\n",
        "# Step 7: Initialize Dendritic Cells (DCs)\n",
        "num_dcs = 20  # Number of Dendritic Cells\n",
        "antigens_per_dc = len(df) * 2 // num_dcs  # Each DC will have twice the number of unique antigens\n",
        "dc_lifespan = np.random.uniform(10, 15, num_dcs)\n",
        "cumulative_csm = np.zeros(num_dcs)\n",
        "cumulative_k = np.zeros(num_dcs)\n",
        "dc_antigen_count = np.zeros(num_dcs)\n",
        "\n",
        "# Step 8: Calculate CSM and K for each DC\n",
        "for i in range(len(df)):\n",
        "    dc_index = i % num_dcs  # Assign antigen to a DC in a round-robin fashion\n",
        "    csm = df['DS'].iloc[i] + df['SS'].iloc[i]\n",
        "    k = df['DS'].iloc[i] - 2 * df['SS'].iloc[i]\n",
        "\n",
        "    # Update cumulative values for the assigned DC\n",
        "    cumulative_csm[dc_index] += csm\n",
        "    cumulative_k[dc_index] += k\n",
        "    dc_antigen_count[dc_index] += 1\n",
        "\n",
        "    # Update DC lifespan\n",
        "    dc_lifespan[dc_index] -= csm\n",
        "    if dc_lifespan[dc_index] <= 0:\n",
        "        # Reset DC\n",
        "        dc_lifespan[dc_index] = np.random.uniform(10, 15)\n",
        "        cumulative_csm[dc_index] = 0\n",
        "        cumulative_k[dc_index] = 0\n",
        "        dc_antigen_count[dc_index] = 0\n",
        "\n",
        "# Step 9: Define threshold and classify based on K value\n",
        "threshold = 0  # If K > 0, classify as Malignant (1), else Benign (0)\n",
        "df['Predicted_M/B'] = np.where(cumulative_k > threshold, 1, 0)\n",
        "\n",
        "# Step 10: Calculate Accuracy\n",
        "accuracy = accuracy_score(df['diagnosis'], df['Predicted_M/B'])\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Step 11: Save the results to a new CSV file\n",
        "df.to_csv('/mnt/data/breast_cancer_ddca_with_predictions.csv', index=False)\n",
        "print(\"Predictions have been saved to 'breast_cancer_ddca_with_predictions.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "66wWBdVSujdK",
        "outputId": "7733ee04-ae80-4010-fe6c-9d335eaf6cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Features based on correlation: Index(['concave points_worst', 'perimeter_worst', 'concave points_mean',\n",
            "       'radius_worst'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Length of values (20) does not match length of index (569)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e99e622f9caf>\u001b[0m in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m# Step 9: Define threshold and classify based on K value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m# If K > 0, classify as Malignant (1), else Benign (0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Predicted_M/B'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcumulative_k\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# Step 10: Calculate Accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4089\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4090\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4091\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4093\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4298\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4299\u001b[0m         \"\"\"\n\u001b[0;32m-> 4300\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4302\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5038\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5039\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5040\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \"\"\"\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (20) does not match length of index (569)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.spatial.distance import euclidean\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step 1: Load the dataset and handle missing values\n",
        "df = pd.read_csv('/content/data.csv')\n",
        "df.drop(columns=['Unnamed: 32'], inplace=True)  # Dropping irrelevant column\n",
        "\n",
        "# Step 2: Convert 'diagnosis' to numerical values (M = 1, B = 0)\n",
        "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
        "\n",
        "# Handle missing values using SimpleImputer (mean strategy)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df[df.columns] = imputer.fit_transform(df[df.columns])\n",
        "\n",
        "# Step 3: Compute correlation with the 'diagnosis' and select top features for DS and SS\n",
        "correlation_matrix = df.corr()\n",
        "class_correlation = correlation_matrix['diagnosis'].sort_values(ascending=False)\n",
        "best_features = class_correlation.index[1:5]  # Top 4 features most correlated with 'diagnosis'\n",
        "print(f\"Best Features based on correlation: {best_features}\")\n",
        "\n",
        "# Step 4: Standardize the selected features for DS and SS computation\n",
        "scaler = StandardScaler()\n",
        "df[best_features] = scaler.fit_transform(df[best_features])\n",
        "\n",
        "# Step 5: Calculate Euclidean distances for each data point from the centroid of normal (Benign) points\n",
        "normal_data = df[df['diagnosis'] == 0][best_features]\n",
        "centroid_normal = normal_data.mean().values  # Calculate the centroid (mean of normal data points)\n",
        "\n",
        "def calculate_euclidean_distance(row, centroid):\n",
        "    return euclidean(row.values, centroid)\n",
        "\n",
        "df['euclidean_distance'] = df[best_features].apply(lambda row: calculate_euclidean_distance(row, centroid_normal), axis=1)\n",
        "\n",
        "# Step 6: Normalize the distances to derive DS and SS\n",
        "max_distance = df['euclidean_distance'].max()\n",
        "min_distance = df['euclidean_distance'].min()\n",
        "\n",
        "df['DS'] = (df['euclidean_distance'] - min_distance) / (max_distance - min_distance)  # Danger Signal\n",
        "df['SS'] = 1 - df['DS']  # Safe Signal (Inverse of Danger Signal)\n",
        "\n",
        "# Step 7: Initialize Dendritic Cells (DCs)\n",
        "num_dcs = 20  # Number of Dendritic Cells\n",
        "antigens_per_dc = len(df) * 2 // num_dcs  # Each DC will have twice the number of unique antigens\n",
        "dc_lifespan = np.random.uniform(10, 15, num_dcs)  # Random lifespan between 10 and 15 for each DC\n",
        "cumulative_csm = np.zeros(num_dcs)\n",
        "cumulative_k = np.zeros(num_dcs)\n",
        "dc_antigen_count = np.zeros(num_dcs)\n",
        "mature_dc_count = np.zeros(len(df))  # To track antigen presence in mature DCs\n",
        "\n",
        "# Step 8: Calculate CSM and K for each DC and determine if the DC matures\n",
        "for i in range(len(df)):\n",
        "    dc_index = i % num_dcs  # Assign antigen to a DC in a round-robin fashion\n",
        "    csm = df['DS'].iloc[i] + df['SS'].iloc[i]\n",
        "    k = df['DS'].iloc[i] - 2 * df['SS'].iloc[i]\n",
        "\n",
        "    # Update cumulative values for the assigned DC\n",
        "    cumulative_csm[dc_index] += csm\n",
        "    cumulative_k[dc_index] += k\n",
        "    dc_antigen_count[dc_index] += 1\n",
        "\n",
        "    # Decrease the lifespan of the DC based on the CSM value\n",
        "    dc_lifespan[dc_index] -= csm\n",
        "\n",
        "    # Check if the DC has matured\n",
        "    if dc_lifespan[dc_index] <= 0:\n",
        "        # Mark antigens presented by this mature DC\n",
        "        mature_dc_count[i] += 1  # Increase count of antigen appearance in mature DCs\n",
        "\n",
        "        # Reset the DC\n",
        "        dc_lifespan[dc_index] = np.random.uniform(10, 15)\n",
        "        cumulative_csm[dc_index] = 0\n",
        "        cumulative_k[dc_index] = 0\n",
        "        dc_antigen_count[dc_index] = 0\n",
        "\n",
        "# Step 9: Classify antigens based on their appearance in mature DCs\n",
        "anomaly_threshold = 0.7  # Threshold for the MCAV (Mature Context Antigen Value)\n",
        "df['MCAV'] = mature_dc_count / num_dcs  # Calculate MCAV for each antigen\n",
        "\n",
        "# Classify antigens as malignant (1) if MCAV is greater than threshold, else benign (0)\n",
        "df['Predicted_M/B'] = np.where(df['MCAV'] > anomaly_threshold, 1, 0)\n",
        "\n",
        "# Step 10: Calculate accuracy by comparing with actual 'diagnosis'\n",
        "accuracy = accuracy_score(df['diagnosis'], df['Predicted_M/B'])\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Step 11: Save the results to a new CSV file\n",
        "df.to_csv('breast_cancer_ddca_with_predictions.csv', index=False)\n",
        "print(\"Predictions have been saved to 'breast_cancer_ddca_with_predictions.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gapq2vm7Yn-v",
        "outputId": "67d6277b-9edc-45fb-fc6d-d593a46dfd35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Features based on correlation: Index(['concave points_worst', 'perimeter_worst', 'concave points_mean',\n",
            "       'radius_worst'],\n",
            "      dtype='object')\n",
            "Accuracy: 62.74%\n",
            "Predictions have been saved to 'breast_cancer_ddca_with_predictions.csv'.\n"
          ]
        }
      ]
    }
  ]
}